%!TEX root = root.tex

\chapter{Discussion}
\label{chap:discussion}

When estimating the mean of a collection of unweighted graphs, motivated by the RDPG model, our methodology takes advantage of the low-rank structure of the graphs by applying low-rank approximation to the entry-wise MLE. 
We give a closed form for the asymptotic relative efficiency between the entry-wise MLE $\bar{A}$ and our estimator $\hat{P}$ in the case of a stochastic blockmodel, demonstrating that when the number of vertices $n$ is sufficiently large, low-rank methods provide a substantial improvement.
In particular, we show that for a stochastic blockmodel with fixed number of blocks $K$, block size proportion $\rho$, and number of graphs $m$, the low-rank estimator $\hat{P}$ has MSE which is on the order of $n$ times lower than the MSE for $\bar{A}$.

Moreover, our estimator outperforms the entry-wise MLE in a cross validation analysis of the SWU4 brain graphs and in low- and full-rank simulation settings.
These results illustrate that $\hat{P}$ performs well even when the low-rank assumption is violated and that $\hat{P}$ is robust and can be applied in practice.

One of the key observations from our real data analysis was that the largest improvements using the low-rank method occurred when the number of graphs $m$ was small, and that it provided only minor improvements or even degraded performance slightly when $m$ was large. 
However, even in large scale studies the low-rank methods will be useful for estimating graph means for subpopulations, e.g.\ the population of females over 60 with some college education.
Using the element-wise sample mean for such small strata, which may have fewer than ten subjects, will frequently result in a degradation of performance.
Similarly, \citet{durante2014nonparametric} used low-rank deviations from a full rank population mean to model collections of graphs and our methods could be easily adapted to those ideas.

While the low-rank methods considered in this work will often offer substantial improvements, further refinements of these methods which account for the particular traits of connectomics data would be useful to improve estimation further.
For example, an issue that arose in our analysis of the connectome dataset was the presence of structural ones in the mean graph for the population. 
These structural ones appear since edges between certain regions of the brain are present in all or nearly all members of the healthy population. 
The low-rank methods tend to miss these always-present edges while the sample mean will always capture them.
Detecting and incorporating structural ones and zeros could yield methods that share the best elements of both methods considered here.

For the SWU4 dataset, we used a cross-validation framework where we compared the estimates based on a subsample to the mean for the held-out set. 
Another option would be to compare the estimates $\bar{A}$ and $\hat{P}$ to the mean for the entire population including the subsample.
Both of these analyses lead to very similar results in the cases presented above, but for various reasons one may prefer one analysis over another.
The cross-validation method is most reasonable from a prediction perspective where prediction about new samples is of interest.
If instead one is interested in learning directly about the mean of a population, especially a finite population, the sub-sampling approach may be the most logical choice.

In practice there is noise in the observed graphs and one may seek to account for this noise with more robust methods. Thus we consider an edge weight gross error model and propose an estimator based on the robust estimation followed by a low-rank decomposition. Under appropriate conditions, theoretical results show that our estimator not only inherits the robust property from robust estimators, but also wins the bias-variance tradeoff by exploiting the low-rank graph structure under appropriate conditions.

% Generalization
In Section~\ref{sec:robust_LLG_theoretical_result}, we present theory based on the exponential distribution with ML$q$E for clarity. Section~\ref{sec:robust_LLG_extension} indicates that these results can be extended to other distributions and robust estimators. Note that the most important condition is Condition~1, which requires that the MLE under the corresponding edge weight and contamination distribution is concentrated so that we obtain the required matrix bounds. This generalization makes the theory more flexible and powerful.

% SBM -> RDPG
In this work, our theoretical analysis is performed mostly in the weighted stochastic blockmodel setting. Note that the results can be extended to the weighted random dot product graph, i.e.\ our estimator does not require the block structure. The reason the results can be extended is that the WSBM assumption is just to ensure $\mathrm{rank}(E[\hat{\bm{P}}^{(q)}])$ has an upper bound under the contamination model that is invariant to the number of vertices. With this assumption on the rank, all the theory still holds in the WRDPG setting. In practice, graphs are not exactly low rank. However, as shown in Figure~\ref{fig:screehist} and Figure~\ref{fig:CCI}, our estimator still provides large improvement with approximate low-rank structure. Thus our method can be applied to a much more general setting instead of being restricted to WSBM.

% Select q
Selecting a good distortion parameter $q$ based on real data in ML$q$E is an important but difficult task.
\citet{qin2017robust} presents a thorough, successful, and decidedly non-trivial example of such a selection methodology in the context of hypothesis testing in the one-sample univariate location problem.
While we use a fixed $q = 0.9$ in our real data experiments without presenting a formal automatic selection methodology,
Figure~\ref{fig:q} demonstrates that a poor choice of $q$ can significantly degrade performance.
We suggest that a program to develop an adaptive approach in our setting,
perhaps along the lines of \citep{qin2017robust}, is a promising avenue for widening the applicability of our estimator.

% Vertex correspondence
The models considered in this work assume that the vertex correspondence across graphs is known. In some applications this may not be the case.  
Our methods may still be applicable after applying graph matching algorithms such as \citep{lyzinski2016graph, lyzinski2015spectral, lyzinski2014seeded, vogelstein2015fast}.

% uncontaminated
% The robust estimators $\hat{P}^{(q)}$ and $\widetilde{P}^{(q)}$ outperform the non-robust ones $\hat{P}^{(1)}$ and $\widetilde{P}^{(1)}$ mainly due to the reduced asymptotic bias in a contaminated model. However, robust estimators like ML$q$E should still provide improvement without contaminations based on finite samples. In this case, the embedding procedure will have a relatively larger impact, leading to a much better estimator $\widetilde{P}^{(q)}$ compared to $\hat{P}^{(q)}$. More work is needed under the uncontaminated setting.

% Other inference
% As we pointed out, improvement for estimation is not only important for the estimation itself, but also can help with other statistical inference procedures. \citet{priebe2015statistical} and \citet{chen2016robust} both discussed vertex classification based on a single unweighted graph with contaminations.
% Moreover, to have a even more general setting, we might want to extend the current RDPG setting to latent positions graphs. \citet{tang2013universally} showed the universally consistency of vertex classification method based on eigen-decomposition.
% More work is needed for inference tasks other than estimation based on multiple weighted graphs.
In general, improvement in estimation performance is important not only for the estimation itself but also is important for subsequent statistical inference procedures such as clustering, vertex classification, etc.
For example, \citet{priebe2015statistical} and \citet{chen2016robust} both discuss vertex classification based on a single unweighted graph with contamination.
Additional investigation into subsequent inference tasks based on multiple contaminated weighted graphs should lead to important refinements and extensions of our robust estimation method.
